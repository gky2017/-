{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망이 학습할 수 있도록 도와주는 지표 : 손실 함수\n",
    "# 학습의 목표는 이 손실 함수의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾는 것\n",
    "\n",
    "# 이미지 분석 : 이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법 : 컴퓨터 비전\n",
    "# 신경망은 이미지를 '있는 그대로' 학습함. 사람의 생각이 개입되지 않음.\n",
    "\n",
    "# 오버피팅(과적합) : 한 데이터셋에만 지나치게 최적화된 상태 이 과적합을 피하는 것이 머신러닝의 주요한 과제임.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111c9d4",
   "metadata": {},
   "source": [
    "### 오차제곱합\n",
    "$$ E = \\frac1 2  \\sum_k (y_k = t_k)^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ee0f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 오차제곱합은 가장 많이 쓰이는 손실 함수이다.\n",
    "import numpy as np\n",
    "\n",
    "def sse(y, t):\n",
    "    return 0.5 * np.sum((y-t) ** 2) \n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "sse(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ed3b0",
   "metadata": {},
   "source": [
    "## 교차 엔트로피 오차\n",
    "\n",
    "$$ E = -\\sum_k t_k  \\log y_k $$\n",
    "* $ y_k $는 신경망의 출력, $ t_k $ 는 정답 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb1c982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307a7dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로그함수에서도 보이다싶이 x가 1일 때 y는 0이 되고, x가 0에 가까워질수록 y의 값은 점점 작아짐.\n",
    "# 식도 마찬가지로 정답에 해당하는 출력이 커질수록 0에 다가가다가 그 출력이 1일 때 0이 됨.\n",
    "import numpy as np\n",
    "\n",
    "def cee(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))  # 아주 작은 값인 delta를 더하는 이유는 np.log()가 0이 되지 않기 위함.\n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cee(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9350d1",
   "metadata": {},
   "source": [
    "## 모든 데이터에 대한 교차 엔트로피 오차\n",
    "\n",
    "$$ E = -\\frac1 N \\sum_n \\sum_k t_nk \\log y_nk  $$\n",
    "\n",
    "* 마지막에 N으로 나누어 정규화함. 이는 '평균 손실 함수'를 구하는 것임.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd0cb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"/Users/yimjaekyoon/Library/CloudStorage/OneDrive-개인/UnderDL\")\n",
    "import numpy as np\n",
    "from mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60758b77",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 훈련 데이터에서 무작위로 10장만 빼내려면?\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size) # 0이상 train_size 미만의 수 중에서 무작위로 batch_size 개를 골라냄\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "t_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a667e",
   "metadata": {},
   "source": [
    "### 배치용 교차 엔트로치 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76e60e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니배치 같은 배치 데이터를 지원하는 교차 엔트로피 오차(cce)는 ?\n",
    "batch_size = 10\n",
    "\n",
    "def cee(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)    \n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수를 사용해야 하는 이유 : 신경망 학습에서는 최적의 매개변수를 탐색할 때 손실 함수의 값을 가능한 한 작게 하는 매개 변수 값을 찾음.\n",
    "# 이 때 매개변수의 미분(기울기)를 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서싷 갱신하는 과정을 반복함.\n",
    "\n",
    "# 정확도를 지표로 삼아서는 안 되는 이유는 미분 값이 대부분 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
